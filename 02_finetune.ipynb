{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe658ff-f881-48bd-9598-cbd23a61680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "## import recformer library\n",
    "from utils import read_json, AverageMeterSet, Ranker\n",
    "from optimization import create_optimizer_and_scheduler\n",
    "from recformer import RecformerModel, RecformerForSeqRec, RecformerTokenizer, RecformerConfig\n",
    "from collator import FinetuneDataCollatorWithPadding, EvalDataCollatorWithPadding\n",
    "from dataloader import RecformerTrainDataset, RecformerEvalDataset\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6099c-2cb6-442d-b247-0afc38f478f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1308880d-d4e4-4351-8426-873e143f8a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args):\n",
    "\n",
    "    train = read_json(args['train_file'], True)\n",
    "    val = read_json(args['dev_file'], True)\n",
    "    test = read_json(args['test_file'], True)\n",
    "    item_meta_dict = json.load(open( args['meta_file'] ))\n",
    "    \n",
    "    item2id = read_json(args['item2id_file'])\n",
    "    id2item = {v:k for k, v in item2id.items()}\n",
    "\n",
    "    item_meta_dict_filted = dict()\n",
    "    for k, v in item_meta_dict.items():\n",
    "        if k in item2id:\n",
    "            item_meta_dict_filted[k] = v\n",
    "\n",
    "    return train, val, test, item_meta_dict_filted, item2id, id2item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee3f30b9-efaa-48c2-868f-ae699df9814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_all_items(model: RecformerModel, tokenizer: RecformerTokenizer, tokenized_items, args):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    items = sorted(list(tokenized_items.items()), key=lambda x: x[0])\n",
    "    items = [ele[1] for ele in items]\n",
    "\n",
    "    item_embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(items), args['batch_size']), ncols=100, desc='Encode all items'):\n",
    "\n",
    "            item_batch = [[item] for item in items[i:i+args['batch_size']]]\n",
    "\n",
    "            inputs = tokenizer.batch_encode(item_batch, encode_item=False)\n",
    "\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = torch.LongTensor(v).to(args['device'])\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            item_embeddings.append(outputs.pooler_output.detach())\n",
    "\n",
    "    item_embeddings = torch.cat(item_embeddings, dim=0)#.cpu()\n",
    "\n",
    "    return item_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a625829-e497-4d25-904d-c57cfc5bef6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed23807b-578a-4ac3-820b-75f69b312c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d1a933c-5d23-4571-8b88-5c38bef4f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "  \"model_name_or_path\": \"../longformer-base-4096\"\n",
    ", \"longformer_ckpt\": '../longformer_ckpt/longformer-base-4096.bin'\n",
    ", \"pretrain_ckpt\":\"../pretrain_ckpt/recformer_seqrec_ckpt.bin\"\n",
    ", \"ckpt\":\"best_model.bin\"\n",
    "    \n",
    ", \"train_file\": \"../finetune_data/Scientific/train.json\"\n",
    ", \"dev_file\": \"../finetune_data/Scientific/val.json\"\n",
    ", \"test_file\": \"../finetune_data/Scientific/test.json\"\n",
    ", \"item2id_file\": \"../finetune_data/Scientific/smap.json\"\n",
    ", \"meta_file\" : \"../finetune_data/Scientific/meta_data.json\"\n",
    "\n",
    ", \"batch_size\" : 2\n",
    ", \"finetune_negative_sample_size\":-1\n",
    ", \"metric_ks\":[10,50]\n",
    ", \"learning_rate\":5e-5\n",
    ", \"weight_decay\":0\n",
    ", \"warmup_steps\":100\n",
    ", \"verbose\":3\n",
    "    \n",
    ", \"num_train_epochs\": 32\n",
    ", \"gradient_accumulation_steps\":8\n",
    "\n",
    ", \"preprocessing_num_workers\" : 0\n",
    ", \"dataloader_num_workers\": 0\n",
    ", \"device\":-1\n",
    ", \"fp16\":True\n",
    ", \"fix_word_embedding\":True\n",
    ", \"temp\" :0.05\n",
    "\n",
    ", \"output_dir\": \"../result/recformer_finetune\"\n",
    "}\n",
    "\n",
    "args['device'] = torch.device('cuda:{}'.format(args['device'])) if args['device']>=0 else torch.device('cpu')\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213629a7-b071-4c27-9d11-4aaa402eae00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0474f351-dfd2-41fd-aa41-5171cf43bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load raw data\n",
    "train, val, test, item_meta_dict, item2id, id2item = load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d841f01-59bb-415a-924c-ed5015ad2c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LongformerTokenizer'. \n",
      "The class this function is called from is 'RecformerTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "## load longformer tokenizer\n",
    "\n",
    "config = RecformerConfig.from_pretrained(args['model_name_or_path'])\n",
    "config.max_attr_num = 3\n",
    "config.max_attr_length = 32\n",
    "config.max_item_embeddings = 51\n",
    "config.attention_window = [64] * 12\n",
    "config.max_token_num = 1024\n",
    "config.item_num = len(item2id)\n",
    "config.finetune_negative_sample_size = args['finetune_negative_sample_size']\n",
    "\n",
    "## load longformer tokenizer\n",
    "tokenizer = RecformerTokenizer.from_pretrained(args['model_name_or_path'], config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf908528-e83c-416b-a6ff-d46a1d5e8b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Preprocessor] Use cache: ../finetune_data/Scientific/meta_data.json.tokenized\n",
      "Item List: 5327\n"
     ]
    }
   ],
   "source": [
    "path_tokenized_items = args['meta_file']+'.tokenized'\n",
    "\n",
    "if os.path.exists(path_tokenized_items):\n",
    "    print(f'[Preprocessor] Use cache: {path_tokenized_items}')\n",
    "    tokenized_items = torch.load(path_tokenized_items)\n",
    "else:\n",
    "    tokenized_items = {}\n",
    "    loop  = 0 \n",
    "    \n",
    "    for item_id, item_attr in item_meta_dict.items():\n",
    "        input_ids, token_type_ids = tokenizer.encode_item(item_attr)\n",
    "        tokenized_items[ item2id[item_id] ] = [input_ids, token_type_ids]\n",
    "        if loop % 1000 == 0:\n",
    "            print(time.ctime(), loop)\n",
    "        loop+=1\n",
    "\n",
    "    torch.save(tokenized_items, path_tokenized_items)\n",
    "\n",
    "print(\"Item List:\",len(tokenized_items)) # 5327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ded66-4d8e-433b-a0f1-2b55546f2c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d3a12-b5c1-4419-9d15-05b7f372872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "\n",
    "finetune_data_collator = FinetuneDataCollatorWithPadding(tokenizer, tokenized_items)\n",
    "eval_data_collator = EvalDataCollatorWithPadding(tokenizer, tokenized_items)\n",
    "\n",
    "train_data = RecformerTrainDataset(train, collator=finetune_data_collator)\n",
    "val_data = RecformerEvalDataset(train, val, test, mode='val', collator=eval_data_collator)\n",
    "test_data = RecformerEvalDataset(train, val, test, mode='test', collator=eval_data_collator)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, \n",
    "                          batch_size=args['batch_size'], \n",
    "                          shuffle=True, \n",
    "                          collate_fn=train_data.collate_fn)\n",
    "dev_loader = DataLoader(val_data, \n",
    "                        batch_size=args['batch_size'],\n",
    "                        collate_fn=val_data.collate_fn)\n",
    "test_loader = DataLoader(test_data, \n",
    "                        batch_size=args['batch_size'],\n",
    "                        collate_fn=test_data.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb9fd1-5cdf-4e59-a207-3b2504a1b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, batch in enumerate(dev_loader):\n",
    "    print(step, batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db4d4f8-8930-4063-961f-7c1841f49f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3b3e6be-b534-4685-9df4-9fee28ea3452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix word embeddings.\n"
     ]
    }
   ],
   "source": [
    "## load checkpoint\n",
    "\n",
    "model = RecformerForSeqRec(config)\n",
    "pretrain_ckpt = torch.load(args['pretrain_ckpt'])\n",
    "model.load_state_dict(pretrain_ckpt, strict=False)\n",
    "model.to(args['device'])\n",
    "\n",
    "if args['fix_word_embedding']:\n",
    "    print('Fix word embeddings.')\n",
    "    for param in model.longformer.embeddings.word_embeddings.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8a3d9-f9b7-4831-825a-392eb8c6452f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a975e46c-fc48-4820-95fa-fb45643ee14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Item Embeddings] Use cache: ../finetune_data/Scientific/meta_data.json.tokenized\n",
      "Initalize item embeddings from vectors.\n",
      "5327\n"
     ]
    }
   ],
   "source": [
    "## item embedding\n",
    "\n",
    "path_item_embeddings =  args['meta_file']+'.embedding'\n",
    "\n",
    "try:\n",
    "    print(f'[Item Embeddings] Use cache: {path_tokenized_items}')\n",
    "    item_embeddings = torch.load(path_item_embeddings)\n",
    "except:\n",
    "    print(f'Encoding items.')\n",
    "    item_embeddings = encode_all_items(model.longformer, tokenizer, tokenized_items, args)\n",
    "    torch.save(item_embeddings, path_item_embeddings)\n",
    "\n",
    "model.init_item_embedding(item_embeddings)\n",
    "model.to(args['device'])\n",
    "\n",
    "print(len(item_embeddings)) # 5327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac17efc9-78b7-4dc5-a688-65f059cfca28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628001a-eb37-4493-b4b5-ac7d2dcfb5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9700ee92-0810-4225-8757-c743a080459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, dataloader, args):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    ranker = Ranker(args['metric_ks'])\n",
    "    average_meter_set = AverageMeterSet()\n",
    "\n",
    "    for batch, labels in tqdm(dataloader, ncols=100, desc='Evaluate'):\n",
    "\n",
    "        for k, v in batch.items():\n",
    "            batch[k] = v.to(args['device'])\n",
    "            \n",
    "        labels = labels.to(args['device'])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            scores = model(**batch)\n",
    "\n",
    "        res = ranker(scores, labels)\n",
    "\n",
    "        metrics = {}\n",
    "        for i, k in enumerate(args['metric_ks']):\n",
    "            metrics[\"NDCG@%d\" % k] = res[2*i]\n",
    "            metrics[\"Recall@%d\" % k] = res[2*i+1]\n",
    "        metrics[\"MRR\"] = res[-3]\n",
    "        metrics[\"AUC\"] = res[-2]\n",
    "\n",
    "        for k, v in metrics.items():\n",
    "            average_meter_set.update(k, v)\n",
    "\n",
    "    average_metrics = average_meter_set.averages()\n",
    "\n",
    "    return average_metrics\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, scheduler, scaler, args):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(tqdm(dataloader, ncols=100, desc='Training')):\n",
    "        for k, v in batch.items():\n",
    "            batch[k] = v.to(args['device'])\n",
    "\n",
    "        if args['fp16']:\n",
    "            with autocast():\n",
    "                loss = model(**batch)\n",
    "        else:\n",
    "            loss = model(**batch)\n",
    "\n",
    "        if args['gradient_accumulation_steps'] > 1:\n",
    "            loss = loss / args['gradient_accumulation_steps']\n",
    "\n",
    "        if args['fp16']:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        if (step + 1) % args['gradient_accumulation_steps'] == 0:\n",
    "            if args['fp16']:\n",
    "                scale_before = scaler.get_scale()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                scale_after = scaler.get_scale()\n",
    "                optimizer_was_run = scale_before <= scale_after\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if optimizer_was_run:\n",
    "                    scheduler.step()\n",
    "\n",
    "            else:\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122a3a93-49ff-4831-a46f-69515e5c761f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41533a-5df7-40aa-8aad-e80a3de495c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_optimization_steps = int(len(train_loader) / args['gradient_accumulation_steps']) * args['num_train_epochs']\n",
    "optimizer, scheduler = create_optimizer_and_scheduler(model, num_train_optimization_steps, args)\n",
    "\n",
    "if args['fp16']:\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "else:\n",
    "    scaler = None\n",
    "\n",
    "test_metrics = eval(model, test_loader, args)\n",
    "print(f'Test set: {test_metrics}')\n",
    "\n",
    "best_target = float('-inf')\n",
    "patient = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b740fe5-439c-4dfa-bd7b-69746cb12bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd2b5f-c41b-4e41-bfc5-c3c4035d3a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9137f3a-0aca-4636-9329-5b3ea63d5b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c90ec-dc1f-4537-a459-a69d2358158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = RecformerEvalDataset(train, val, test, mode='test', collator=eval_data_collator)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, \n",
    "                          batch_size=args['batch_size'], \n",
    "                          shuffle=True, \n",
    "                          collate_fn=train_data.collate_fn)\n",
    "dev_loader = DataLoader(val_data, \n",
    "                        batch_size=args['batch_size'],\n",
    "                        collate_fn=val_data.collate_fn)\n",
    "test_loader = DataLoader(test_data, \n",
    "                        batch_size=args['batch_size'],\n",
    "                        collate_fn=test_data.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e964316-af53-46f7-8e81-acfff8ab4ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193, 346, 353, 1278, 186, 61, 237, 0, 1268]\n",
      "[4173]\n",
      "[2936, 4125, 4345, 751]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "loop = 0\n",
    "\n",
    "for batch, labels in test_data:\n",
    "    print(batch), print(labels)\n",
    "    if loop ==1:\n",
    "        break\n",
    "    else:\n",
    "        loop+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3700398-6697-415d-93e2-68186aff886d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d24dde27-ab7e-4583-8603-78a27c0ca17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: tensor([4173,    0])\n",
      "predicts: tensor([[18.4771],\n",
      "        [15.0274]])\n",
      "tensor([   0., 1528.])\n",
      "k: 10\n",
      "indicator: tensor([1., 0.])\n",
      "ncdg: tensor([1., 0.])\n",
      "hr: tensor([1., 0.])\n",
      "MRR: tensor([1.0000e+00, 6.5402e-04])\n",
      "AUC: tensor([1.0000, 0.7132])\n",
      "k: 50\n",
      "indicator: tensor([1., 0.])\n",
      "ncdg: tensor([1., 0.])\n",
      "hr: tensor([1., 0.])\n",
      "MRR: tensor([1.0000e+00, 6.5402e-04])\n",
      "AUC: tensor([1.0000, 0.7132])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "ranker = Ranker(args['metric_ks'])\n",
    "average_meter_set = AverageMeterSet()\n",
    "\n",
    "loop = 0\n",
    "\n",
    "for batch, labels in test_loader:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = model(**batch) # [batch_size, 5327]\n",
    "\n",
    "    res = ranker(scores, labels)\n",
    "\n",
    "    metrics = {}\n",
    "    for i, k in enumerate(args['metric_ks']):\n",
    "        metrics[\"NDCG@%d\" % k] = res[2*i]\n",
    "        metrics[\"Recall@%d\" % k] = res[2*i+1]\n",
    "    metrics[\"MRR\"] = res[-3]\n",
    "    metrics[\"AUC\"] = res[-2]\n",
    "\n",
    "    for k, v in metrics.items():\n",
    "        average_meter_set.update(k, v)\n",
    "\n",
    "    break\n",
    "\n",
    "# average_metrics = average_meter_set.averages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6289fa85-5c75-435b-92dd-7c75f114dbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4173],\n",
       "        [   0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d54c5-00ce-45dc-8a4c-31db2eb09a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7621d75-633b-47f3-b73c-812adecae32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[18.4771],\n",
      "        [15.0274]])\n"
     ]
    }
   ],
   "source": [
    "predicts = scores[torch.arange(scores.size(0)), labels.squeeze()].unsqueeze(-1) \n",
    "print(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c59d60d-6bdb-40ef-b0e4-ac02c4bb5f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 1528])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (predicts < scores).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd038f9-2ddf-4eb7-805a-f85353df7599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf3d814-369a-4b7f-8b83-7c91cac02740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e3c17d-bde3-4ab3-ab15-827a7d298485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667647f3-5b1c-4f5e-b550-ae25227dff35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6507ab7-60ba-47d2-a1d7-200833e4c3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355d9721-777c-44de-90f2-3c7be583d101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c18da-dd11-41b0-9d2b-31a764db2457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "371e71fb-0444-4f78-94c0-232a111c8a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "MAX_VAL = 1e4\n",
    "\n",
    "\n",
    "class Ranker(nn.Module):\n",
    "    def __init__(self, metrics_ks):\n",
    "        super().__init__()\n",
    "        self.ks = metrics_ks\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, scores, labels):\n",
    "        labels = labels.squeeze()\n",
    "        print(\"labels:\", labels)\n",
    "        \n",
    "        try:\n",
    "            loss = self.ce(scores, labels).item()\n",
    "        except:\n",
    "            print(scores.size())\n",
    "            print(labels.size())\n",
    "            loss = 0.0\n",
    "        \n",
    "        predicts = scores[torch.arange(scores.size(0)), labels].unsqueeze(-1) # gather perdicted values\n",
    "        print(\"predicts:\", predicts)\n",
    "        \n",
    "        valid_length = (scores > -MAX_VAL).sum(-1).float()\n",
    "        rank = (predicts < scores).sum(-1).float()\n",
    "        print(\"rank:\", rank)\n",
    "        res = []\n",
    "        for k in self.ks:\n",
    "            print(\"k:\", k)\n",
    "            indicator = (rank < k).float()\n",
    "            print(\"indicator:\", indicator)\n",
    "            print(\"ncdg:\", ((1 / torch.log2(rank+2)) * indicator))\n",
    "            print(\"hr:\", indicator)\n",
    "            print(\"MRR:\", (1 / (rank+1)))\n",
    "            print(\"AUC:\", (1 - (rank/valid_length)) )\n",
    "            res.append(\n",
    "                ((1 / torch.log2(rank+2)) * indicator).mean().item() # ndcg@k\n",
    "            ) \n",
    "            res.append(\n",
    "                indicator.mean().item() # hr@k\n",
    "            )\n",
    "        res.append((1 / (rank+1)).mean().item()) # MRR\n",
    "        res.append((1 - (rank/valid_length)).mean().item()) # AUC\n",
    "\n",
    "        return res + [loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6066a9-958f-4350-aaab-70019b3f62a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels: tensor([4173,    0])\n",
    "predicts: tensor([[18.4771],\n",
    "        [15.0274]])\n",
    "rank in 5327 items: tensor([   0., 1528.])\n",
    "\n",
    "\n",
    "k: 10\n",
    "indicator: tensor([1., 0.])\n",
    "ncdg: tensor([1., 0.])\n",
    "hr: tensor([1., 0.])\n",
    "MRR: tensor([1.0000e+00, 6.5402e-04])\n",
    "AUC: tensor([1.0000, 0.7132])\n",
    "\n",
    "k: 50\n",
    "indicator: tensor([1., 0.])\n",
    "ncdg: tensor([1., 0.])\n",
    "hr: tensor([1., 0.])\n",
    "MRR: tensor([1.0000e+00, 6.5402e-04])\n",
    "AUC: tensor([1.0000, 0.7132])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526e6d4-8730-474f-9ee4-2f9e35856e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a10eb1-27fe-443f-8e01-2153d87143e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd27e94-f2ed-4b10-bd43-3a0603b754d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e2ab4f-09db-4435-97c7-f057d42b0ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f062e26-ada6-40f4-8ce8-de2012fb6fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415a3a7-80d6-4b6d-be28-9d8bc75981f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1292ea-ecd1-4c9e-958f-3427f0d8eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(args['num_train_epochs']):\n",
    "\n",
    "    item_embeddings = encode_all_items(model.longformer, tokenizer, tokenized_items, args)\n",
    "    model.init_item_embedding(item_embeddings)\n",
    "\n",
    "    train_one_epoch(model, train_loader, optimizer, scheduler, scaler, args)\n",
    "    \n",
    "    if (epoch + 1) % args['verbose'] == 0:\n",
    "        dev_metrics = eval(model, dev_loader, args)\n",
    "        print(f'Epoch: {epoch}. Dev set: {dev_metrics}')\n",
    "\n",
    "        if dev_metrics['NDCG@10'] > best_target:\n",
    "            print('Save the best model.')\n",
    "            best_target = dev_metrics['NDCG@10']\n",
    "            patient = 5\n",
    "            torch.save(model.state_dict(), path_ckpt)\n",
    "        \n",
    "        else:\n",
    "            patient -= 1\n",
    "            if patient == 0:\n",
    "                break\n",
    "\n",
    "print('Load best model in stage 1.')\n",
    "model.load_state_dict(torch.load(path_ckpt))\n",
    "\n",
    "patient = 3\n",
    "\n",
    "for epoch in range(args['num_train_epochs']):\n",
    "\n",
    "    train_one_epoch(model, train_loader, optimizer, scheduler, scaler, args)\n",
    "    \n",
    "    if (epoch + 1) % args['verbose'] == 0:\n",
    "        dev_metrics = eval(model, dev_loader, args)\n",
    "        print(f'Epoch: {epoch}. Dev set: {dev_metrics}')\n",
    "\n",
    "        if dev_metrics['NDCG@10'] > best_target:\n",
    "            print('Save the best model.')\n",
    "            best_target = dev_metrics['NDCG@10']\n",
    "            patient = 3\n",
    "            torch.save(model.state_dict(), path_ckpt)\n",
    "        \n",
    "        else:\n",
    "            patient -= 1\n",
    "            if patient == 0:\n",
    "                break\n",
    "\n",
    "print('Test with the best checkpoint.')  \n",
    "model.load_state_dict(torch.load(path_ckpt))\n",
    "test_metrics = eval(model, test_loader, args)\n",
    "print(f'Test set: {test_metrics}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b524ad-1cdf-4ddb-874a-7a4db33a697c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1c0d1-5137-47c5-9081-b6020db2a253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb5a7c-6553-4bed-8634-ce94df360433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad538bdc-6fd2-4359-8e78-056df2e97b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef2172-1a7a-422e-b508-4c168e571d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aaf7b8-1463-4100-bb43-b143a67b5a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from recformer import RecformerModel, RecformerConfig, RecformerForSeqRec\n",
    "\n",
    "config = RecformerConfig.from_pretrained('longformer-base-4096')\n",
    "config.max_attr_num = 3  # max number of attributes for each item\n",
    "config.max_attr_length = 32 # max number of tokens for each attribute\n",
    "config.max_item_embeddings = 51 # max number of items in a sequence +1 for cls token\n",
    "config.attention_window = [64] * 12 # attention window for each layer\n",
    "\n",
    "model = RecformerModel(config) \n",
    "model.load_state_dict(torch.load('recformer_ckpt.bin')) # RecformerModel = recformer_ckpt.bin\n",
    "\n",
    "rec_model = RecformerForSeqRec(config)\n",
    "rec_model.load_state_dict(torch.load('recformer_seqrec_ckpt.bin'), strict=False)\n",
    "# strict=False because RecformerForSeqRec doesn't have lm_head\n",
    "\n",
    "# missing_keys=[]\n",
    "# unexpected_keys=['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias'])\n",
    "# lm_head.decoder.bias torch.Size([50265]) is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad3beee-ece6-4b32-83c9-7c22d97e6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = torch.load('recformer_seqrec_ckpt.bin')\n",
    "for k, v in _.items():\n",
    "    print(k, v.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e20607-4be3-4849-add0-2183429c8f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.state_dict().items():\n",
    "    if not torch.all(param == rec_model.state_dict()[ 'longformer.'+name]):\n",
    "        print(name)\n",
    "    else:\n",
    "        print(\"Match:\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ba8ef-53bf-4271-938f-edf1804f68c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8587d4-fc3a-4a16-8782-cae0250908c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142eff3-7b2d-40ce-939f-23c98a23a0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
